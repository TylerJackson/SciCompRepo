{
 "metadata": {
  "name": "Project3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Project 3 Polynomial Interpolation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "By Tyler Jackson"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Date: 11/5/2013"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "    Class: Math 3316"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    In this project we evaluated two different types of polynomial interpolation to approximate a function.  The first we evaluated was Newton's method, and the second was Lagrange's method.  Newton's method we calculated in a file called newton_interp.cpp and tested in test_newton.cpp.  We then compared this newton method to the lagrange method in terms of the time necessary to calculate each.  We varied the number of nodes, and the number of values we evaluate each at.  This in turn changes the number of calculations necessary to interpolate each.  We then applied the lagrange method to two dimensions, which we implemented in our langrage2D.cpp file.  Previously we have used our interpolation methods to approximate the function e^(x*x).  Our next step was to use the lagrange 2D method to approximate the runge function.  The runge function is structured to be horrible for interpolation.  In order to approximate this function we used uniformly spaced nodes.  Lastly, we repeated this process using the chebyshev function to calculate nodes.  The chebyshev function is supposed to provide nodes that are really good for interpolation.  \n",
      "    \n",
      "    Our first output was the approximation of the function e^(x*x) using the newton_polynomial.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Newton method approximation:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "interpolant and error using 7 nodes:\n",
      "      z        f(z)               p(z)              error\n",
      "   -0.833    2.0025962113905    2.0046415106121   0.0020453\n",
      "   -0.500    1.2840254166877    1.2837194253706   0.000305991\n",
      "   -0.167    1.0281671774377    1.0282214646324   5.42872e-05\n",
      "    0.167    1.0281671774377    1.0282214646324   5.42872e-05\n",
      "    0.500    1.2840254166877    1.2837194253706   0.000305991\n",
      "    0.833    2.0025962113905    2.0046415106121   0.0020453\n",
      "Coefficients were calculated\n",
      "\n",
      "interpolant and error using 16 nodes:\n",
      "      z        f(z)               p(z)              error\n",
      "   -0.933    2.3895644506425    2.3895644868934   3.62509e-08\n",
      "   -0.800    1.8964808793050    1.8964808756531   3.65187e-09\n",
      "   -0.667    1.5596234976068    1.5596234982683   6.61538e-10\n",
      "   -0.533    1.3290234766114    1.3290234764294   1.81974e-10\n",
      "   -0.400    1.1735108709918    1.1735108710621   7.02429e-11\n",
      "   -0.267    1.0737005192985    1.0737005192621   3.64411e-11\n",
      "   -0.133    1.0179367430886    1.0179367431134   2.47915e-11\n",
      "    0.000    1.0000000000000    0.9999999999782   2.1832e-11\n",
      "    0.133    1.0179367430886    1.0179367431134   2.47904e-11\n",
      "    0.267    1.0737005192985    1.0737005192621   3.64417e-11\n",
      "    0.400    1.1735108709918    1.1735108710621   7.02434e-11\n",
      "    0.533    1.3290234766114    1.3290234764294   1.81973e-10\n",
      "    0.667    1.5596234976068    1.5596234982683   6.61539e-10\n",
      "    0.800    1.8964808793050    1.8964808756531   3.65187e-09\n",
      "    0.933    2.3895644506425    2.3895644868934   3.62509e-08\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    It is useful here to compare our approximation using newton's method to the approximation and error from using the lagrange method.  This is just the output from running the test_lagrange routine provided to us.  We would expect to see similar results."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Lagrange method approximation:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "interpolant and error using 7 nodes:\n",
      "      z        f(z)               p(z)              error\n",
      "   -0.833    2.0025962113905    2.0046415106121   0.0020453\n",
      "   -0.500    1.2840254166877    1.2837194253706   0.000305991\n",
      "   -0.167    1.0281671774377    1.0282214646324   5.42872e-05\n",
      "    0.167    1.0281671774377    1.0282214646324   5.42872e-05\n",
      "    0.500    1.2840254166877    1.2837194253706   0.000305991\n",
      "    0.833    2.0025962113905    2.0046415106121   0.0020453\n",
      "\n",
      "interpolant and error using 16 nodes:\n",
      "      z        f(z)               p(z)              error\n",
      "   -0.933    2.3895644506425    2.3895644868934   3.62509e-08\n",
      "   -0.800    1.8964808793050    1.8964808756531   3.65187e-09\n",
      "   -0.667    1.5596234976068    1.5596234982683   6.61536e-10\n",
      "   -0.533    1.3290234766114    1.3290234764294   1.81974e-10\n",
      "   -0.400    1.1735108709918    1.1735108710621   7.02436e-11\n",
      "   -0.267    1.0737005192985    1.0737005192621   3.64411e-11\n",
      "   -0.133    1.0179367430886    1.0179367431134   2.47906e-11\n",
      "    0.000    1.0000000000000    0.9999999999782   2.18322e-11\n",
      "    0.133    1.0179367430886    1.0179367431134   2.47906e-11\n",
      "    0.267    1.0737005192985    1.0737005192621   3.64411e-11\n",
      "    0.400    1.1735108709918    1.1735108710621   7.02436e-11\n",
      "    0.533    1.3290234766114    1.3290234764294   1.81974e-10\n",
      "    0.667    1.5596234976068    1.5596234982683   6.61538e-10\n",
      "    0.800    1.8964808793050    1.8964808756531   3.65187e-09\n",
      "    0.933    2.3895644506425    2.3895644868934   3.62509e-08\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "        The next main routine I ran compared the run times for the lagrange polynomial versus the newton polynomial.  In order to be thorough we adjusted the number of nodes used, as well as the number of points we evaluated it at.  As you can see the run time for the newton method is consistently less than the run time for the lagrange method.  As you increase the number of nodes (n), the run time for both increases, and as you increase the evaluation points (m) the run time increases even more."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comparison of the two methods:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Lagrange Time 1 ---- n=10, m=1000   : 2 milliseconds\n",
      "Newton Time   1 ---- n=10, m=1000   : 1 milliseconds\n",
      "Lagrange Time 2 ---- n=10, m=10000  : 16 milliseconds\n",
      "Newton Time   2 ---- n=10, m=10000  : 7 milliseconds\n",
      "Lagrange Time 3 ---- n=10, m=100000 : 130 milliseconds\n",
      "Newton Time   3 ---- n=10, m=100000 : 100 milliseconds\n",
      "Lagrange Time 4 ---- n=25, m=1000   : 6 milliseconds\n",
      "Newton Time   4 ---- n=25, m=1000   : 6 milliseconds\n",
      "Lagrange Time 5 ---- n=25, m=10000  : 89 milliseconds\n",
      "Newton Time   5 ---- n=25, m=10000  : 50 milliseconds\n",
      "Lagrange Time 6 ---- n=25, m=100000 : 679 milliseconds\n",
      "Newton Time   6 ---- n=25, m=100000 : 367 milliseconds\n",
      "Lagrange Time 7 ---- n=50, m=1000   : 33 milliseconds\n",
      "Newton Time   7 ---- n=50, m=1000   : 14 milliseconds\n",
      "Lagrange Time 8 ---- n=50, m=10000  : 246 milliseconds\n",
      "Newton Time   8 ---- n=50, m=10000  : 127 milliseconds\n",
      "Lagrange Time 9 ---- n=50, m=100000 : 2412 milliseconds\n",
      "Newton Time   9 ---- n=50, m=100000 : 1183 milliseconds\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    The times above should increase exponentially, because the algorithm is n squared efficiency.  Next we applied the lagrange method to two dimensions.  This meant we performed each calculation from the one dimension case n more times.  Therefore, the lagrange 2D method is of n cubed efficiency.  For the lagrange 2D plots we used the lagrange 2D ipython notebook provided (see attached).  We plotted the true value for the function we were trying to interpolate as well as the approximation from interpolation.  Since we interpolated using 7 nodes and 16, we had two plots for our approximation.  As you can see the 3 plots all look very similar.  We then calculated the error, and compared it to a know error for this equation/interpolation (which was provided to us).  In the ipython notebook we provided, we were given a message to tell us if our error was less than or equal to what the known error should be and we Next we plotted our data for the runge interpolation using evenly spaced nodes.  I received to success notifications meaning my lagrange 2D method was calculated and implemented correctly.  Next we moved on to interpolating the runge function.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpolating the Runge Function"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    Recall that the runge function is a horrible function for interpolation, and therefore our lagrange2D method really gets put to the test.  We first interpolated our runge function with uniformly spaced nodes over our interval.  If you refer to the runge_2D ipython notebook (see attached), we first plotted the true values for the runge function.  Our next two plots were our interpolation approximation of the runge function using 11 nodes and 21 nodes.  As you can see the two approximations don't appear to be similar at all, and the approximation has most of its data points located near the corners.  This is because we chose to use uniformly spaced nodes which can often be problematic.  To fix this we repeated the approximations using nodes calculated from the chebyshev function.  We then plotted these approximations in our runge_2D ipython notebook.  As you can see these approximations appear to be much closer to the plot of the true values of the runge function.  We then plotted the error of the four different approximations from the true value.  As expected the error for the first two approximations is highest at the corners.  Notice the magnitudes of the first two error plots.  The error for the approximation using regularly spaced nodes is over 8 for 11 nodes, and close to 25,000 for 21 nodes.  Then if you look at the two error plots for when we used the chebyshev nodes you can see the magnitudes are much smaller.  For the approximation using 7 chebyshev nodes the error is less than .1, and for the approximation using 21 chebyshev nodes the error is less than .012.  This supports the theory that the chebyshev nodes are better for interpolating the runge function than the regularly spaced nodes.  However, we can take this one step further.  If we examine our error calculating formula we have a product term (often referred to as omega) that drives the error.  This term is dependent on where we choose the nodes, and differs greatly between regularly spaced nodes and chebyshev nodes.  If you refer to the plot of our product using chebyshev nodes (second to last plot in runge_2D) you can see that the product maximum and minimum are consistent throught the plot.  Also, you can see that the magnitude is around 40,000.  Then we plotted the product from the regularly spaced nodes (last plot in runge_2D).  Here, the magnitude of the product is much higher at the edges, and is slightly greater than 400,000.  This means that the product in the error term is a factor of ten greater when using regularly spaced nodes versus chebyshev nodes."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    For this project we examined the potential differences in using different types of interpolation methods, as well as the difference when varying the nodes of an interpolation.  In conclusion the newton method of interpolation is faster in run time than the lagrange method, and similar in accuracy.  We also found that when choosing nodes, often regularly spaced nodes can be problematic.  When examining the product in the error term of the approximations we saw the chebyshev nodes resulted in a more uniform product with a much smaller magnitude.  Therefore, we can conclude that the chebyshev nodes are a better choice of nodes when interpolating compared to uniformly spaced nodes.  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}